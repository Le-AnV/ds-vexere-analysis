import streamlit as st
import pandas as pd
import numpy as np

from sklearn.preprocessing import RobustScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import os, glob


# =========================================================
# 0. HÃ€M FEATURE ENGINEERING DÃ™NG CHUNG CHO TRAIN & PREDICT
# =========================================================
def feature_engineering(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()

    # 1. Loáº¡i cÃ¡c dÃ²ng price_original = 0
    df = df[df["price_original"] != 0].copy()

    # 2. REAL PRICE
    df["real_price"] = np.where(
        df["price_discounted"] == 0,
        df["price_original"],
        df["price_discounted"],
    )

    # 3. LOG PRICE
    df["log_price"] = np.log1p(df["real_price"])

    # 4. TIME & GIÃ THEO PHÃšT
    df["duration_minutes_log"] = np.log1p(df["duration_minutes"])
    df["price_per_minute"] = df["real_price"] / df["duration_minutes"]

    # 5. DISCOUNT RATE
    df["discount_rate"] = 1 - df["price_discounted"] / df["price_original"]

    # 6. SERVICE SCORE
    service_cols = ["rating_staff_attitude", "rating_service_quality", "rating_comfort"]
    df["service_score"] = df[service_cols].mean(axis=1)

    # 7. TRUST SCORE
    trust_cols = ["rating_safety", "rating_punctuality", "rating_info_accuracy"]
    df["trust_score"] = df[trust_cols].mean(axis=1)

    # 8. WILSON SCORE
    def wilson_lower_bound(p, n, z=1.96):
        if n == 0:
            return 0.0
        denom = 1 + z**2 / n
        centre = p + z * z / (2 * n)
        margin = z * np.sqrt((p * (1 - p) + z * z / (4 * n)) / n)
        return (centre - margin) / denom

    df["p"] = df["rating_overall"] / 5.0
    df["wilson_score"] = df.apply(
        lambda r: wilson_lower_bound(r["p"], r["reviewer_count"]), axis=1
    )
    df.drop(columns=["p"], inplace=True)

    # 9. PRICE PER SEAT
    df["price_per_seat"] = df["real_price"] / df["number_of_seat"]

    # 10. PRICEâ€“RATING RATIO (á»•n Ä‘á»‹nh)
    df["price_rating_ratio_stable"] = df["wilson_score"] / df["log_price"]

    # 11. FAIRNESS INDEX
    df["fairness_index"] = df["wilson_score"] / np.sqrt(df["real_price"])

    # 12. LOG thÃªm
    df["log_price_per_minute"] = np.log1p(df["price_per_minute"])
    df["log_price_per_seat"] = np.log1p(df["price_per_seat"])

    return df


# =========================================================
# 1. TIÃŠU Äá»€
# =========================================================
st.title("ğŸš PhÃ¢n cá»¥m chuyáº¿n xe khÃ¡ch theo giÃ¡ & cháº¥t lÆ°á»£ng dá»‹ch vá»¥")

st.write(
    """
    Flow:
    1) DÃ¹ng dá»¯ liá»‡u trong `data/processed` Ä‘á»ƒ huáº¥n luyá»‡n KMeans (K = 3).  
    2) Sau Ä‘Ã³ nháº­p tay chuyáº¿n xe má»›i trÃªn web Ä‘á»ƒ xem nÃ³ rÆ¡i vÃ o cá»¥m nÃ o vÃ  Ã½ nghÄ©a cá»§a cá»¥m Ä‘Ã³.
    """
)

# =========================================================
# 2. LOAD Dá»® LIá»†U TRAIN Tá»ª CSV
# =========================================================
st.header("1ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh KMeans tá»« dá»¯ liá»‡u gá»‘c")

folder_path = "data/processed"
csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

if not csv_files:
    st.error(f"KhÃ´ng tÃ¬m tháº¥y file CSV nÃ o trong thÆ° má»¥c: {folder_path}")
    st.stop()

dfs = []
for f in csv_files:
    tmp = pd.read_csv(f)
    dfs.append(tmp)

df_train_raw = pd.concat(dfs, ignore_index=True)

st.write(f"âœ… ÄÃ£ load {len(csv_files)} file CSV, tá»•ng sá»‘ dÃ²ng: {df_train_raw.shape[0]}")
st.dataframe(df_train_raw.head())

# CÃ¡c cá»™t sá»‘ cáº§n thiáº¿t
numeric_cols = [
    "price_original",
    "price_discounted",
    "duration_minutes",
    "rating_overall",
    "rating_safety",
    "rating_info_accuracy",
    "rating_staff_attitude",
    "rating_comfort",
    "rating_service_quality",
    "rating_punctuality",
    "reviewer_count",
    "number_of_seat",
]

df_train_raw[numeric_cols] = df_train_raw[numeric_cols].apply(
    pd.to_numeric, errors="coerce"
)
df_train_raw = df_train_raw.dropna(subset=numeric_cols)

if df_train_raw.shape[0] < 3:
    st.error("Dá»¯ liá»‡u train sau khi lÃ m sáº¡ch < 3 dÃ²ng, khÃ´ng Ä‘á»§ Ä‘á»ƒ phÃ¢n cá»¥m K=3.")
    st.stop()

# =========================================================
# 3. FEATURE ENGINEERING CHO Dá»® LIá»†U TRAIN
# =========================================================
df_train_fe = feature_engineering(df_train_raw)

st.subheader("ğŸ“ Má»™t sá»‘ feature Ä‘Ã£ táº¡o trÃªn dá»¯ liá»‡u train")
st.dataframe(
    df_train_fe[
        [
            "real_price",
            "log_price",
            "service_score",
            "trust_score",
            "wilson_score",
            "fairness_index",
        ]
    ].head()
)

# Feature dÃ¹ng Ä‘á»ƒ phÃ¢n cá»¥m (giá»‘ng notebook)
features = [
    "wilson_score",
    "log_price",
    "fairness_index",
    "trust_score",
    "service_score",
]

df_cluster_train = df_train_fe[features].dropna().copy()
df_cluster_train = df_cluster_train.drop_duplicates()

if df_cluster_train.shape[0] <= 3:
    st.error("Sau khi drop NaN/duplicates, dá»¯ liá»‡u train cÃ²n quÃ¡ Ã­t Ä‘á»ƒ phÃ¢n cá»¥m K=3.")
    st.stop()

# =========================================================
# 4. SCALE + TRAIN KMEANS Vá»šI K = 3
# =========================================================
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(df_cluster_train[features])

K = 3
model = KMeans(n_clusters=K, random_state=40, n_init=10)
train_labels = model.fit_predict(X_train_scaled)

df_cluster_train = df_cluster_train.copy()
df_cluster_train["cluster"] = train_labels

# Join cluster vá» láº¡i df_train_fe (theo index)
df_train_result = df_train_fe.join(df_cluster_train["cluster"], how="left")

st.success("âœ… ÄÃ£ huáº¥n luyá»‡n KMeans vá»›i K = 3 trÃªn dá»¯ liá»‡u CSV.")
st.subheader("ğŸ“„ Má»™t pháº§n dá»¯ liá»‡u train sau phÃ¢n cá»¥m")
st.dataframe(df_train_result.head())

# =========================================================
# 5. PCA TRÃŠN Dá»® LIá»†U TRAIN (OPTIONAL)
# =========================================================
if df_cluster_train.shape[0] >= 2:
    st.subheader("ğŸ“Š PCA 2D trÃªn dá»¯ liá»‡u train")

    pca = PCA(n_components=2)
    X_train_pca = pca.fit_transform(X_train_scaled)

    fig, ax = plt.subplots()
    ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=train_labels, cmap="viridis")
    ax.set_xlabel("PCA 1")
    ax.set_ylabel("PCA 2")
    ax.set_title("PCA Visualization (Train Data, K = 3)")

    st.pyplot(fig)

# =========================================================
# 6. NHáº¬P Dá»® LIá»†U Má»šI TRÃŠN WEB â†’ Dá»° ÄOÃN Cá»¤M
# =========================================================
st.header("2ï¸âƒ£ Nháº­p chuyáº¿n xe má»›i Ä‘á»ƒ xem thuá»™c cá»¥m nÃ o")

st.write(
    """
    Nháº­p cÃ¡c thÃ´ng tin thÃ´ cho chuyáº¿n xe má»›i (giÃ¡, rating, thá»i gian, sá»‘ gháº¿, sá»‘ reviewer).  
    App sáº½ dÃ¹ng **cÃ¹ng pipeline feature + scaler + model KMeans** Ä‘Ã£ train Ä‘á»ƒ dá»± Ä‘oÃ¡n cá»¥m
    vÃ  giáº£i thÃ­ch Ã½ nghÄ©a cá»¥m.
    """
)

# Gá»£i Ã½ má»™t dÃ²ng máº«u Ä‘á»ƒ dá»… nháº­p
sample_new = {
    "price_original": [400000],
    "price_discounted": [350000],
    "duration_minutes": [660],
    "rating_overall": [4.6],
    "rating_safety": [4.7],
    "rating_info_accuracy": [4.6],
    "rating_staff_attitude": [4.7],
    "rating_comfort": [4.5],
    "rating_service_quality": [4.5],
    "rating_punctuality": [4.8],
    "reviewer_count": [500],
    "number_of_seat": [34],
}

df_new_input = st.data_editor(
    pd.DataFrame(sample_new),
    num_rows="dynamic",
    key="manual_new_trips",
)

# ====== GIáº¢I THÃCH Ã NGHÄ¨A Cá»¤M ======
cluster_meanings = {
    0: {
        "name": "Ngon â€“ Bá»• â€“ Ráº»",
        "description": """
ğŸ“Œ **Cá»¥m 0 â€“ â€œNgon â€“ Bá»• â€“ Ráº»â€**  
â€¢ GiÃ¡ vÃ© tháº¥p nháº¥t trong 3 nhÃ³m  
â€¢ Cháº¥t lÆ°á»£ng dá»‹ch vá»¥ tá»‘t, á»•n Ä‘á»‹nh  
â€¢ Äiá»ƒm Wilson cao â†’ má»©c hÃ i lÃ²ng bá»n vá»¯ng  
â€¢ Ráº¥t tá»‘i Æ°u vá» chi phÃ­ vÃ  giÃ¡ trá»‹  

ğŸ‘‰ Chuyáº¿n xe thuá»™c cá»¥m 0 thÆ°á»ng lÃ  *dá»‹ch vá»¥ cháº¥t lÆ°á»£ng tá»‘t nhÆ°ng giÃ¡ váº«n má»m, Ä‘Ã¡ng Ä‘á»“ng tiá»n bÃ¡t gáº¡o*.
""",
    },
    1: {
        "name": "GiÃ¡ áº£o â€“ Cháº¥t lÆ°á»£ng tháº¥p",
        "description": """
ğŸ“Œ **Cá»¥m 1 â€“ â€œGiÃ¡ áº£o â€“ Cháº¥t lÆ°á»£ng tháº¥pâ€**  
â€¢ GiÃ¡ vÃ© cao nháº¥t thá»‹ trÆ°á»ng  
â€¢ Cháº¥t lÆ°á»£ng dá»‹ch vá»¥ tháº¥p nháº¥t  
â€¢ Äiá»ƒm Wilson tháº¥p â†’ Ä‘Ã¡nh giÃ¡ kÃ©m á»•n Ä‘á»‹nh  

ğŸ‘‰ Chuyáº¿n xe thuá»™c cá»¥m 1 thÆ°á»ng lÃ  *giÃ¡ cao nhÆ°ng cháº¥t lÆ°á»£ng khÃ´ng tÆ°Æ¡ng xá»©ng* 
(vÃ­ dá»¥: Ä‘á»™c quyá»n tuyáº¿n, tÄƒng giÃ¡ mÃ¹a cao Ä‘iá»ƒm nhÆ°ng phá»¥c vá»¥ kÃ©m).
""",
    },
    2: {
        "name": "Cao cáº¥p â€“ ÄÃ¡ng tiá»n",
        "description": """
ğŸ“Œ **Cá»¥m 2 â€“ â€œCao cáº¥p â€“ ÄÃ¡ng tiá»nâ€**  
â€¢ GiÃ¡ vÃ© cao  
â€¢ Cháº¥t lÆ°á»£ng dá»‹ch vá»¥ tá»‘t nháº¥t  
â€¢ Äiá»ƒm tin cáº­y (Wilson, Trust Score) cao  

ğŸ‘‰ Chuyáº¿n xe thuá»™c cá»¥m 2 lÃ  *dá»‹ch vá»¥ cao cáº¥p â€“ â€œtiá»n nÃ o cá»§a náº¥yâ€*, 
phÃ¹ há»£p khÃ¡ch hÃ ng Æ°u tiÃªn tráº£i nghiá»‡m, an toÃ n vÃ  sá»± chuyÃªn nghiá»‡p.
""",
    },
}

# ====== NÃšT Dá»° ÄOÃN ======
if st.button("ğŸš€ Dá»± Ä‘oÃ¡n cá»¥m cho dá»¯ liá»‡u má»›i"):
    if df_new_input.shape[0] == 0:
        st.warning("ChÆ°a cÃ³ dÃ²ng nÃ o trong báº£ng dá»¯ liá»‡u má»›i.")
    else:
        df_new = df_new_input.copy()
        df_new[numeric_cols] = df_new[numeric_cols].apply(
            pd.to_numeric, errors="coerce"
        )
        df_new = df_new.dropna(subset=numeric_cols)

        if df_new.shape[0] == 0:
            st.warning("Táº¥t cáº£ dÃ²ng má»›i Ä‘á»u thiáº¿u dá»¯ liá»‡u á»Ÿ cÃ¡c cá»™t quan trá»ng.")
        else:
            # Feature engineering cho dá»¯ liá»‡u má»›i
            df_new_fe = feature_engineering(df_new)

            # Láº¥y Ä‘Ãºng cÃ¡c feature Ä‘Ã£ dÃ¹ng khi train
            df_new_cluster = df_new_fe[features].dropna().copy()

            if df_new_cluster.shape[0] == 0:
                st.warning("KhÃ´ng táº¡o Ä‘Æ°á»£c Ä‘á»§ feature cho dá»¯ liá»‡u má»›i (NaN háº¿t).")
            else:
                # Scale báº±ng scaler Ä‘Ã£ FIT trÃªn train
                X_new_scaled = scaler.transform(df_new_cluster[features])

                # Dá»± Ä‘oÃ¡n cá»¥m báº±ng model Ä‘Ã£ FIT
                new_labels = model.predict(X_new_scaled)

                df_new_fe = df_new_fe.loc[df_new_cluster.index].copy()
                df_new_fe["predicted_cluster"] = new_labels

                st.subheader("ğŸ”® Káº¿t quáº£ dá»± Ä‘oÃ¡n cá»¥m cho dá»¯ liá»‡u má»›i")
                st.dataframe(
                    df_new_fe[
                        [
                            "price_original",
                            "price_discounted",
                            "duration_minutes",
                            "rating_overall",
                            "reviewer_count",
                            "number_of_seat",
                            "real_price",
                            "log_price",
                            "wilson_score",
                            "fairness_index",
                            "trust_score",
                            "service_score",
                            "predicted_cluster",
                        ]
                    ]
                )

                # ======= HIá»†N GIáº¢I THÃCH Cá»¤M CHO Tá»ªNG NHÃ“M XUáº¤T HIá»†N =======
                st.subheader("ğŸ“˜ Giáº£i thÃ­ch Ã½ nghÄ©a cÃ¡c cá»¥m xuáº¥t hiá»‡n trong dá»± Ä‘oÃ¡n")

                for c in sorted(df_new_fe["predicted_cluster"].unique()):
                    st.markdown(f"### ğŸ¯ Cluster {c} â€“ {cluster_meanings[c]['name']}")
                    st.markdown(cluster_meanings[c]["description"])
                    idx_list = df_new_fe.index[df_new_fe["predicted_cluster"] == c]
                    st.caption(f"CÃ¡c dÃ²ng thuá»™c cá»¥m {c}: {list(idx_list)}")
