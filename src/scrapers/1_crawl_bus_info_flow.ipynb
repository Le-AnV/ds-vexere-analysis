{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189f503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bca114",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2b7dc",
   "metadata": {},
   "source": [
    "## 1. Price parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5a86a",
   "metadata": {},
   "source": [
    "- `price_original`: Gi√° g·ªëc (gi√° ch∆∞a gi·∫£m, ƒë∆°n v·ªã: VND)\n",
    "- `price_discounted`: Gi√° khuy·∫øn m√£i (gi√° ƒë√£ gi·∫£m, ƒë∆°n v·ªã: VND)\n",
    "- `precent_discount`: Ph·∫ßn trƒÉm s·ªë ti·ªÅn ƒë√£ gi·∫£m (ƒë∆°n v·ªã: %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ef385",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- C√≥ gi√° khuy·∫øn m√£i: \n",
    "    &lt;fare-sale&gt; ch·ª©a gi√° khuy·∫øn m√£i\n",
    "        &lt;fareSmall&gt; ch·ª©a gi√° g·ªëc v√† ph·∫ßn trƒÉm ∆∞u ƒë√£i\n",
    "- Kh√¥ng c√≥ gi√° khuy·∫øn m√£i:\n",
    "    &lt;fare&gt; ch·ª©a gi√° g·ªëc\n",
    "        &lt;fareSmall&gt; kh√¥ng ch·ª©a d·ªØ li·ªáu\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86992d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_regular_fare(block) -> bool:\n",
    "    \"\"\"\n",
    "    Ki·ªÉm tra chuy·∫øn xe c√≥ khuy·∫øn m√£i hay kh√¥ng.\n",
    "\n",
    "    Returns:\n",
    "        True  -> kh√¥ng c√≥ gi√° khuy·∫øn m√£i (fare)\n",
    "        False -> c√≥ gi√° khuy·∫øn m√£i (fare-sale)\n",
    "    \"\"\"\n",
    "    fare = block.find(\"div\", class_=\"fare\")\n",
    "    return bool(fare)\n",
    "\n",
    "\n",
    "def parse_regular_fare(block):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t gi√° v√© cho chuy·∫øn kh√¥ng c√≥ khuy·∫øn m√£i.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"price_original\": str,  # Gi√° g·ªëc\n",
    "            \"price_discounted\": None,\n",
    "            \"percent_discount\": None\n",
    "        }\n",
    "    \"\"\"\n",
    "    fare = block.find(\"div\", class_=\"fare\")\n",
    "    price_original = (\n",
    "        fare.get_text(strip=True)\n",
    "        if fare else None\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"price_original\": price_original,\n",
    "        \"price_discounted\": None,\n",
    "        \"percent_discount\": None,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_discount_metadata(block):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t gi√° g·ªëc v√† ph·∫ßn trƒÉm gi·∫£m gi√° t·ª´ th·∫ª 'fareSmall'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (price_original, percent_discount)\n",
    "    \"\"\"\n",
    "    fare_small = block.find(\"div\", class_=\"fareSmall\")\n",
    "    price_original = (\n",
    "        fare_small.find(\"div\", class_=\"small\").get_text(strip=True)\n",
    "        if fare_small else None\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        percent_discount = (\n",
    "            fare_small.find(\"div\", class_=\"percent\").get_text(strip=True)\n",
    "            if fare_small and fare_small.find(\"div\", class_=\"percent\")\n",
    "            else None\n",
    "        )\n",
    "    except Exception:\n",
    "        percent_discount = None\n",
    "\n",
    "    return price_original, percent_discount\n",
    "\n",
    "\n",
    "def parse_discounted_fare(block):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t gi√° v√© cho chuy·∫øn c√≥ khuy·∫øn m√£i.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"price_original\": str,   # Gi√° g·ªëc\n",
    "            \"price_discounted\": str, # Gi√° sau gi·∫£m\n",
    "            \"percent_discount\": str  # Ph·∫ßn trƒÉm gi·∫£m\n",
    "        }\n",
    "    \"\"\"\n",
    "    price_original, percent_discount = parse_discount_metadata(block)\n",
    "\n",
    "    fare_sale = block.find(\"div\", class_=\"fare-sale\")\n",
    "    price_discounted = (\n",
    "        fare_sale.get_text(strip=True).strip() if fare_sale and fare_sale.get_text(strip=True) else None\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"price_original\": price_original,\n",
    "        \"price_discounted\": price_discounted,\n",
    "        \"percent_discount\": percent_discount,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ab590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(block):\n",
    "    '''\n",
    "    Tr√≠ch xu·∫•t d·ªØ li·ªáu v·ªÅ gi√° c·ªßa chuy·∫øn xe \\n\n",
    "    Tr·∫£ v·ªÅ: gi√° g·ªëc, gi√° khuy·∫øn m√£i (n·∫øu c√≥), ph·∫ßn trƒÉm khuy·∫øn m√£i (n·∫øu c√≥)\n",
    "    '''\n",
    "    \n",
    "    if is_regular_fare(block):\n",
    "        return parse_regular_fare(block)\n",
    "    else:\n",
    "        return parse_discounted_fare(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d2a06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06813c2d",
   "metadata": {},
   "source": [
    "## 2. Bus info parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab4b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_trip_bus_info(container):\n",
    "    '''\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin t·ª´ m·ªôt container ch·ª©a th√¥ng tin chuy·∫øn ƒëi. \\n\n",
    "    Tr·∫£ v·ªÅ Tuple: t√™n nh√† xe, ƒë√°nh gi√° nh√† xe, lo·∫°i gh·∫ø.\n",
    "    '''\n",
    "    \n",
    "    # bus name / company name\n",
    "    bus_element = container.find('div', class_='bus-name')\n",
    "    company_name = bus_element.get_text(strip=True) if bus_element else None\n",
    "\n",
    "    # bus rating\n",
    "    rating_element = container.find('div', class_='bus-rating').find('span')\n",
    "    bus_rating = rating_element.get_text(strip=True) if rating_element else None\n",
    "\n",
    "    # seat_type\n",
    "    seat_type = container.find('div', class_='seat-type')\n",
    "    seat_type = seat_type.get_text(strip=True) if seat_type else None\n",
    "\n",
    "    return {\n",
    "        'company_name': company_name,\n",
    "        'bus_rating': bus_rating,\n",
    "        'seat_type': seat_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ccd4e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f321dd",
   "metadata": {},
   "source": [
    "## 3. Route parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b6af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D·ªØ li·ªáu n√†y n·∫±m ·ªü √¥ filter chuy·∫øn ƒëi\n",
    "\n",
    "def parse_route_info(block):\n",
    "    '''\n",
    "    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ filter c·ªßa trang web \\n\n",
    "    Tr·∫£ v·ªÅ: ng√†y kh·ªüi h√†nh, n∆°i xu·∫•t ph√°t (th√†nh ph·ªë hi·ªán t·∫°i), n∆°i ƒë·∫øn (n∆°i ƒë·∫∑t v√© ƒë·∫øn)\n",
    "    '''\n",
    "\n",
    "    departure_date, start_point, destination = None, None, None\n",
    "\n",
    "    try:\n",
    "        departure_date = block.find('p', class_='date-input-value').get_text(strip=True)\n",
    "        start_point = block.find(id=\"from_input\").get('value')\n",
    "        destination = block.find(id=\"to_input\").get('value')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        'departure_date': departure_date,\n",
    "        'start_point': start_point,\n",
    "        'destination': destination\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0374e21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80b078",
   "metadata": {},
   "source": [
    "## 4. Details trip info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea04c89",
   "metadata": {},
   "source": [
    "### 4.1 Departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55134a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D·ªØ li·ªáu n√†y n·∫±m trong container > 'from_content'\n",
    "\n",
    "def parse_departure_trip_info(from_content):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin ƒëi·ªÉm ƒëi t·ª´ m·ªôt container 'from_content'.\n",
    "    Tr·∫£ v·ªÅ m·ªôt tuple ch·ª©a: gi·ªù kh·ªüi h√†nh, ƒë·ªãa ƒëi·ªÉm ƒë√≥n kh√°ch.\n",
    "    \"\"\"\n",
    "    # n·∫øu container kh√¥ng t·ªìn t·∫°i, tr·∫£ v·ªÅ gi√° tr·ªã None cho t·∫•t c·∫£\n",
    "    if not from_content:\n",
    "        return None, None\n",
    "\n",
    "    # departure time\n",
    "    departure_time_element = from_content.find('div', class_='hour')\n",
    "    departure_time = departure_time_element.get_text(strip=True) if departure_time_element else None\n",
    "\n",
    "    # departure place\n",
    "    from_place_tag = from_content.find('div', class_='place')\n",
    "    pickup_point = from_place_tag.get_text(strip=True) if from_place_tag else None\n",
    "    \n",
    "    return {\n",
    "        'departure_time': departure_time,\n",
    "        'pickup_point': pickup_point\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4c055",
   "metadata": {},
   "source": [
    "### 4.2 Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9818dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arrival_trip_info(to_content):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin ƒëi·ªÉm ƒë·∫øn t·ª´ m·ªôt container 'to_content'.\\n\n",
    "    Tr·∫£ v·ªÅ m·ªôt tuple ch·ª©a: ng√†y ƒë·∫øn, th·ªùi gian ƒë·∫øn, ƒëi·ªÉm tr·∫£ kh√°ch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # n·∫øu container kh√¥ng t·ªìn t·∫°i, tr·∫£ v·ªÅ gi√° tr·ªã None cho t·∫•t c·∫£\n",
    "    if not to_content:\n",
    "        return None, None, None\n",
    "\n",
    "    # l·∫•y ng√†y ƒë·∫øn\n",
    "    date_arrival_tag = to_content.find('span', class_=\"text-date-arrival-time\")\n",
    "    arrival_date = date_arrival_tag.get_text(strip=True) if date_arrival_tag else None\n",
    "    \n",
    "    \n",
    "    # l·∫•y gi·ªù v√† ƒë·ªãa ƒëi·ªÉm tr·∫£ kh√°ch\n",
    "    content_to_info = to_content.find('div', class_='content-to-info')\n",
    "    if content_to_info:\n",
    "        to_hour_tag = content_to_info.find('div', class_='hour')\n",
    "        arrival_time = to_hour_tag.get_text(strip=True) if to_hour_tag else None\n",
    "        \n",
    "        dropoff_place_element = content_to_info.find('div', class_='place')\n",
    "        dropoff_point = dropoff_place_element.get_text(strip=True) if dropoff_place_element else None\n",
    "        \n",
    "    return {\n",
    "        'arrival_date': arrival_date,\n",
    "        'arrival_time': arrival_time,\n",
    "        'dropoff_point': dropoff_point\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb088b09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acecffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trip_timing(container):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt v·ªÅ chuy·∫øn ƒëi (gi·ªù, n∆°i ƒëi - ƒë·∫øn, th·ªùi gian di chuy·ªÉn). \\n\n",
    "    Tr·∫£ v·ªÅ: dict ch·ª©a th√¥ng tin kh·ªüi h√†nh, ƒëi·ªÉm ƒë·∫øn v√† th·ªùi l∆∞·ª£ng chuy·∫øn.\n",
    "    \"\"\"\n",
    "    \n",
    "    # T√¨m kh·ªëi ch·ª©a th√¥ng tin ƒëi v√† ƒë·∫øn\n",
    "    from_to_content = container.find('div', class_=\"from-to-content\")\n",
    "\n",
    "    # N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ dict r·ªóng c√≥ c·∫•u tr√∫c s·∫µn\n",
    "    if not from_to_content:\n",
    "        return {\n",
    "            \"duration\": None,\n",
    "            \"departure_time\": None,\n",
    "            \"pickup_point\": None,\n",
    "            \"departure_date\": None,\n",
    "            \"arrival_date\": None,\n",
    "            \"arrival_time\": None,\n",
    "            \"dropoff_point\": None,\n",
    "        }\n",
    "\n",
    "    # L·∫•y th√¥ng tin n∆°i kh·ªüi h√†nh\n",
    "    from_content = from_to_content.find('div', class_='content from')\n",
    "    dict_departure_info = parse_departure_trip_info(from_content)\n",
    "\n",
    "    # L·∫•y th√¥ng tin n∆°i ƒë·∫øn\n",
    "    to_content = from_to_content.find('div', class_='content to')\n",
    "    dict_arrival_info = parse_arrival_trip_info(to_content)\n",
    "\n",
    "    # L·∫•y th·ªùi gian di chuy·ªÉn\n",
    "    duration_tag = from_to_content.find('div', class_=\"duration\")\n",
    "    duration = duration_tag.get_text(strip=True) if duration_tag else None\n",
    "\n",
    "    # G·ªôp to√†n b·ªô th√¥ng tin l·∫°i\n",
    "    trip_data = dict_departure_info | dict_arrival_info | {'duration': duration}\n",
    "    \n",
    "    return trip_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab51647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_trip_info(block):\n",
    "    '''\n",
    "    T·∫≠p h·ª£p to√†n b·ªô th√¥ng tin c·ªßa 1 chuy·∫øn xe t·ª´ 1 kh·ªëi d·ªØ li·ªáu (block). \\n\n",
    "    Tr·∫£ v·ªÅ: dict ch·ª©a th√¥ng tin xe, l·ªãch tr√¨nh v√† gi√° v√©.\n",
    "    '''\n",
    "    \n",
    "    # L·∫•y th√¥ng tin ch√≠nh c·ªßa nh√† xe\n",
    "    dict_bus_info = parser_trip_bus_info(block)\n",
    "    \n",
    "    # L·∫•y th√¥ng tin gi·ªù ƒëi - gi·ªù ƒë·∫øn, ƒëi·ªÉm ƒë√≥n - tr·∫£\n",
    "    dict_trip_details = parse_trip_timing(block)\n",
    "    \n",
    "    # L·∫•y th√¥ng tin gi√° v√© (gi√° g·ªëc, gi√° khuy·∫øn m√£i)\n",
    "    dict_price = parse_price(block)\n",
    "    \n",
    "    # G·ªôp t·∫•t c·∫£ d·ªØ li·ªáu v√†o 1 dictionary duy nh·∫•t\n",
    "    trip_data = dict_bus_info | dict_trip_details | dict_price\n",
    "    \n",
    "    return trip_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af68d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a9ec8",
   "metadata": {},
   "source": [
    "## Parsing rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7447a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ratings_from_container(container):\n",
    "    '''\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin ƒë√°nh gi√° (rating) c·ªßa t·ª´ng nh√† xe trong 1 container. \\n\n",
    "    Tr·∫£ v·ªÅ: list c√°c c·∫∑p (rate_title, rate_point) ho·∫∑c [(None, None)] n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu.\n",
    "    '''\n",
    "    try:\n",
    "        ratings = []\n",
    "        rate_divs = container.find_all('div', class_='rate-title')   # T√¨m t·∫•t c·∫£ kh·ªëi ch·ª©a th√¥ng tin ƒë√°nh gi√°\n",
    "        \n",
    "        for rate_div in rate_divs:\n",
    "            rate_ps = rate_div.find_all('p')   # M·ªói ph·∫ßn t·ª≠ ch·ª©a ti√™u ƒë·ªÅ v√† ƒëi·ªÉm\n",
    "            if len(rate_ps) >= 2:\n",
    "                rate_title = rate_ps[0].get_text(strip=True)   # Ti√™u ƒë·ªÅ ƒë√°nh gi√°\n",
    "                rate_point = rate_ps[1].get_text(strip=True)   # ƒêi·ªÉm ƒë√°nh gi√°\n",
    "                ratings.append((rate_title, rate_point))       # L∆∞u v√†o danh s√°ch\n",
    "        \n",
    "        if ratings:\n",
    "            return ratings     # Tr·∫£ v·ªÅ danh s√°ch n·∫øu c√≥ d·ªØ li·ªáu\n",
    "        else:\n",
    "            return [(None, None)]   # Kh√¥ng c√≥ d·ªØ li·ªáu ƒë√°nh gi√°\n",
    "            \n",
    "    except Exception:\n",
    "        return [(None, None)]   # Tr∆∞·ªùng h·ª£p l·ªói v·∫´n tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63350b6f",
   "metadata": {},
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2cc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_trips(soup):\n",
    "    '''\n",
    "    Tr√≠ch xu·∫•t v√† g·ªôp th√¥ng tin chuy·∫øn xe, tuy·∫øn ƒë∆∞·ªùng v√† ƒë√°nh gi√° nh√† xe th√†nh m·ªôt DataFrame duy nh·∫•t.\n",
    "    Tr·∫£ v·ªÅ: DataFrame ch·ª©a to√†n b·ªô d·ªØ li·ªáu chuy·∫øn xe.\n",
    "    '''\n",
    "    dict_route = parse_route_info(soup)  # L·∫•y th√¥ng tin tuy·∫øn ƒë∆∞·ªùng (ƒëi - ƒë·∫øn)\n",
    "    containers = soup.find_all(\"div\", class_=\"container\")  # T√¨m t·∫•t c·∫£ container ch·ª©a chuy·∫øn xe\n",
    "\n",
    "    lst_trips_info = []\n",
    "\n",
    "    for container in containers:\n",
    "        # ---- L·∫•y th√¥ng tin chuy·∫øn xe ----\n",
    "        dict_trip_info = compile_trip_info(container) | dict_route\n",
    "\n",
    "        # ---- L·∫•y th√¥ng tin ƒë√°nh gi√° ----\n",
    "        ratings = parse_ratings_from_container(container)\n",
    "\n",
    "        # ratings l√† list c√°c tuple [(rate_title, rate_point), ...]\n",
    "        # ta chuy·ªÉn n√≥ th√†nh dict d·∫°ng {'rating_T√™nTi√™uƒê·ªÅ': ƒëi·ªÉm}\n",
    "        rating_dict = {\n",
    "            f\"{title}\": point\n",
    "            for title, point in ratings\n",
    "            if title is not None and point is not None\n",
    "        }\n",
    "\n",
    "        # ---- G·ªôp th√¥ng tin chuy·∫øn xe v√† rating ----\n",
    "        full_info = dict_trip_info | rating_dict\n",
    "\n",
    "        # ---- ƒê∆∞a v√†o DataFrame ----\n",
    "        df_trip_info = pd.DataFrame([full_info])\n",
    "        lst_trips_info.append(df_trip_info)\n",
    "\n",
    "    # ---- G·ªôp to√†n b·ªô chuy·∫øn xe l·∫°i th√†nh 1 dataframe ----\n",
    "    all_trips_info = pd.concat(lst_trips_info, ignore_index=True)\n",
    "\n",
    "    return all_trips_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ccd096",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cefdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException, StaleElementReferenceException\n",
    "import time, random\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26a6b6",
   "metadata": {},
   "source": [
    "## 5. Handle Button logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34075b14",
   "metadata": {},
   "source": [
    "### 5.1. Button `Xem th√™m chuy·∫øn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e820cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_load_more(driver, max_click=7, max_wait=15):\n",
    "    \"\"\"\n",
    "    Click n√∫t 'Xem th√™m chuy·∫øn' an to√†n, t·ªëi ƒëa max_click l·∫ßn.\n",
    "    - D√πng JS click ƒë·ªÉ tr√°nh l·ªói b·ªã che.\n",
    "    - T·ª± d·ª´ng n·∫øu kh√¥ng th·∫•y container m·ªõi xu·∫•t hi·ªán.\n",
    "    \"\"\"\n",
    "    wait = WebDriverWait(driver, max_wait)\n",
    "    click_count = 0\n",
    "    fail_count = 0\n",
    "    MAX_FAIL = 3\n",
    "\n",
    "    for _ in range(max_click):\n",
    "        try:\n",
    "            containers_before = len(driver.find_elements(By.CLASS_NAME, \"container\"))\n",
    "            btn = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"load-more\")))\n",
    "\n",
    "            if not btn.is_displayed() or not btn.is_enabled():\n",
    "                print(\"N√∫t 'Xem th√™m chuy·∫øn' kh√¥ng kh·∫£ d·ª•ng.\")\n",
    "                break\n",
    "\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", btn)\n",
    "            time.sleep(random.uniform(0.8, 1.5))\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            click_count += 1\n",
    "\n",
    "            time.sleep(random.uniform(2.0, 3.0))\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    lambda d: len(d.find_elements(By.CLASS_NAME, \"container\")) > containers_before\n",
    "                )\n",
    "                fail_count = 0\n",
    "            except TimeoutException:\n",
    "                fail_count += 1\n",
    "                if fail_count >= MAX_FAIL:\n",
    "                    print(\"Kh√¥ng th·∫•y container m·ªõi sau nhi·ªÅu l·∫ßn ‚Üí d·ª´ng.\")\n",
    "                    break\n",
    "\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            print(\"Kh√¥ng c√≤n n√∫t 'Xem th√™m chuy·∫øn' ‚Üí d·ª´ng.\")\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        except Exception:\n",
    "            fail_count += 1\n",
    "            if fail_count >= MAX_FAIL:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "    print(f\"Ho√†n t·∫•t ‚Äî ƒë√£ click {click_count} l·∫ßn.\")\n",
    "    return click_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d708a76",
   "metadata": {},
   "source": [
    "### 5.2. Button `Xem c√°c ƒë√°nh gi√°`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bdb9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ratings(driver, click_prob=0.65, delay_range=(0.5, 1.2)):\n",
    "    \"\"\"\n",
    "    M·ªü ng·∫´u nhi√™n c√°c ph·∫ßn ƒë√°nh gi√° (rating) tr√™n trang Vexere.\n",
    "    - Kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn click.\n",
    "    - Random b·ªè qua m·ªôt s·ªë n√∫t ƒë·ªÉ gi·∫£ l·∫≠p h√†nh vi ng∆∞·ªùi th·∫≠t.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        stars = driver.find_elements(By.CLASS_NAME, \"bus-rating-button\")\n",
    "        if not stars:\n",
    "            print(\"Kh√¥ng t√¨m th·∫•y n√∫t ƒë√°nh gi√°.\")\n",
    "            return 0\n",
    "\n",
    "        total = len(stars)\n",
    "        clicks = 0\n",
    "\n",
    "        for i in range(total):\n",
    "            if random.random() > click_prob:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                stars = driver.find_elements(By.CLASS_NAME, \"bus-rating-button\")\n",
    "                if i >= len(stars):\n",
    "                    break\n",
    "                star = stars[i]\n",
    "\n",
    "                if not star.is_displayed():\n",
    "                    continue\n",
    "\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", star)\n",
    "                time.sleep(random.uniform(*delay_range))\n",
    "                driver.execute_script(\"arguments[0].click();\", star)\n",
    "                clicks += 1\n",
    "                time.sleep(random.uniform(*delay_range))\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        print(f\"ƒê√£ click {clicks}/{total} n√∫t ƒë√°nh gi√°.\")\n",
    "        return clicks\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Kh√¥ng th·ªÉ m·ªü ph·∫ßn ƒë√°nh gi√°.\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99928e00",
   "metadata": {},
   "source": [
    "### 5.3. Button `T√¨m ki·∫øm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7c2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_search(driver, retries=3):\n",
    "    \"\"\"\n",
    "    Click v√†o n√∫t t√¨m ki·∫øm tr√™n trang Vexere (an to√†n, t·ª± scroll, retry n·∫øu l·ªói).\n",
    "    \"\"\"\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            btn = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"button-search\")))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", btn)\n",
    "            time.sleep(0.5)\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            print(\"Click v√†o n√∫t t√¨m ki·∫øm th√†nh c√¥ng\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            print(\"Click t√¨m ki·∫øm l·ªói, th·ª≠ l·∫°i\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    print(\"Kh√¥ng th·ªÉ click v√†o n√∫t t√¨m ki·∫øm\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4498ff",
   "metadata": {},
   "source": [
    "## 6. Automate the process of filtering website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1317c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_date_components(days=0):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ ng√†y v√† th√°ng-nƒÉm m·ª•c ti√™u c√°ch hi·ªán t·∫°i `days` ng√†y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    days : int, optional\n",
    "        S·ªë ng√†y c·ªông th√™m t·ª´ ng√†y hi·ªán t·∫°i (m·∫∑c ƒë·ªãnh = 0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {'day': '15', 'month_year': '10-2025'}\n",
    "    \"\"\"\n",
    "    # Ng√†y m·ª•c ti√™u = ng√†y hi·ªán t·∫°i + days ng√†y\n",
    "    target_date = datetime.today() + timedelta(days=days)\n",
    "    month_year = f\"{target_date.month:02d}-{target_date.year}\"\n",
    "    day = str(target_date.day)\n",
    "\n",
    "    return {\n",
    "        'day': day,\n",
    "        'month_year': month_year\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62fa7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_search_filters(driver, start_city: str, destination_city: str, days=0):\n",
    "    \"\"\"\n",
    "    Ch·ªçn ƒëi·ªÉm ƒëi, ƒëi·ªÉm ƒë·∫øn v√† ng√†y kh·ªüi h√†nh tr√™n trang Vexere.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    driver : webdriver\n",
    "        ƒê·ªëi t∆∞·ª£ng Selenium WebDriver ƒëang ƒëi·ªÅu khi·ªÉn tr√¨nh duy·ªát.\n",
    "    start_city : str\n",
    "        T√™n th√†nh ph·ªë kh·ªüi h√†nh.\n",
    "    destination_city : str\n",
    "        T√™n th√†nh ph·ªë ƒëi·ªÉm ƒë·∫øn.\n",
    "    days : int, optional\n",
    "        S·ªë ng√†y t√≠nh t·ª´ h√¥m nay ƒë·ªÉ ch·ªçn ng√†y ƒëi (m·∫∑c ƒë·ªãnh = 0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True n·∫øu ch·ªçn ng√†y th√†nh c√¥ng, False n·∫øu x·∫£y ra l·ªói.\n",
    "    \"\"\"\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    try:\n",
    "        # Nh·∫≠p n∆°i ƒëi v√† n∆°i ƒë·∫øn\n",
    "        departure_input = wait.until(EC.presence_of_element_located((By.ID, 'from_input')))\n",
    "        destination_input = wait.until(EC.presence_of_element_located((By.ID, 'to_input')))\n",
    "\n",
    "        departure_input.clear()\n",
    "        destination_input.clear()\n",
    "\n",
    "        departure_input.send_keys(start_city)\n",
    "        destination_input.send_keys(destination_city)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # M·ªü ph·∫ßn ch·ªçn ng√†y ƒëi\n",
    "        date_btn = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"departure-date-select\")))\n",
    "        date_btn.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # L·∫•y th√¥ng tin ng√†y v√† th√°ng c·∫ßn ch·ªçn\n",
    "        target = get_target_date_components(days)\n",
    "        target_day = target['day']\n",
    "        target_month = target['month_year']\n",
    "\n",
    "        # T√¨m kh·ªëi th√°ng (c√≥ th·ªÉ d√πng '-' ho·∫∑c '_')\n",
    "        try:\n",
    "            month_section = driver.find_element(By.ID, target_month)\n",
    "        except:\n",
    "            month_section = driver.find_element(By.ID, target_month.replace('-', '_'))\n",
    "\n",
    "        # T√¨m t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ ng√†y trong th√°ng\n",
    "        day_elements = month_section.find_elements(By.CSS_SELECTOR, \"p.day\")\n",
    "\n",
    "        for day in day_elements:\n",
    "            if day.text.strip() == target_day:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", day)\n",
    "                time.sleep(0.3)\n",
    "                driver.execute_script(\"arguments[0].click();\", day)\n",
    "                return True\n",
    "\n",
    "        print(\"Kh√¥ng t√¨m th·∫•y ng√†y c·∫ßn ch·ªçn.\")\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi ch·ªçn b·ªô l·ªçc t√¨m ki·∫øm: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760e892",
   "metadata": {},
   "source": [
    "# FLOW OFFICIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77a3bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7897f2",
   "metadata": {},
   "source": [
    "## Crawl rating data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032405d",
   "metadata": {},
   "source": [
    "# -- Main --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6d2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab83c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL = 'https://vexere.com/'\n",
    "\n",
    "# # Danh s√°ch tuy·∫øn\n",
    "# arrivals_HaNoi = ['H√† Giang','Qu·∫£ng Ninh','Thanh H√≥a','SaPa','Ninh B√¨nh']#['H·∫£i Ph√≤ng','Ngh·ªá An','S∆°n La']\n",
    "# arrivals_SaiGon = ['Gia Lai','B√¨nh Thu·∫≠n','Ninh Thu·∫≠n','ƒê·∫Øk L·∫Øk','Ph√∫ Y√™n','Nha Trang','B√† R·ªãa-V≈©ng T√†u']\n",
    "\n",
    "\n",
    "# departure_city = 'H√† N·ªôi'\n",
    "# days_offset = 1 #int(input(\"\"))\n",
    "\n",
    "# # L·∫•y ng√†y / th√°ng c·∫ßn crawl\n",
    "# target_date = get_target_date_components(days_offset)\n",
    "# day = target_date['day']\n",
    "# month_year = target_date['month_year']\n",
    "# month_years = month_year.replace('-', '_')\n",
    "\n",
    "# # Crawl t·ª´ng tuy·∫øn\n",
    "# for arrival_city in arrivals_HaNoi:\n",
    "\n",
    "#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "#     driver.get(URL)\n",
    "\n",
    "#     print(f\"ƒêang crawl: {departure_city} ‚Üí {arrival_city}\")\n",
    "\n",
    "#     filter_success = set_search_filters(\n",
    "#         driver,\n",
    "#         start_city=departure_city,\n",
    "#         destination_city=arrival_city,\n",
    "#         days=days_offset\n",
    "#     )\n",
    "\n",
    "#     if not filter_success:\n",
    "#         print(f\"Kh√¥ng th·ªÉ ch·ªçn ng√†y cho {arrival_city}\")\n",
    "#         continue\n",
    "\n",
    "#     time.sleep(2)\n",
    "#     click_search(driver)    # Click t√¨m ki·∫øm sau khi l·ªçc d·ªØ li·ªáu\n",
    "#     time.sleep(2.5)\n",
    "#     click_load_more(driver,5) # Click xem th√™m ƒë·ªÉ th·∫•y ƒëc nhi·ªÅu chuy·∫øn xe\n",
    "    \n",
    "#     expand_ratings(driver, 0.6)  # M·ªü c√°c th√¥ng tin ƒë√°nh gi√° t·ª´ng chuy·∫øn\n",
    "#     time.sleep(1.5)\n",
    "\n",
    "#     # Parse d·ªØ li·ªáu HTML\n",
    "#     soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "#     try:\n",
    "#         df_trips_info = extract_all_trips(soup)\n",
    "\n",
    "#         save_path = f\"../../data/processed/{departure_city}_{arrival_city}_{day}_{month_years}.csv\"\n",
    "#         df_trips_info.to_csv(save_path, index=False, encoding='utf-8')\n",
    "\n",
    "#         print(f\"L·∫•y d·ªØ li·ªáu {arrival_city} th√†nh c√¥ng! ‚Üí {save_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         html_path = f\"../../data/site/{departure_city}_{arrival_city}_{day}_{month_years}.html\"\n",
    "#         with open(html_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(soup.prettify()) \n",
    "#         print(f\"L∆∞u HTML ƒë·ªÉ debug: {html_path}\\n{e}\")\n",
    "\n",
    "# # ƒê√≥ng tr√¨nh duy·ªát sau khi ho√†n t·∫•t\n",
    "#     driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8083e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö¶ B·∫Øt ƒë·∫ßu crawl t·ª´ H√† N·ªôi cho ng√†y: 1/11-2025\n",
      "\n",
      "üöç ƒêang crawl: H√† N·ªôi ‚Üí H√† Giang\n",
      "üí• L·ªói driver khi x·ª≠ l√Ω H√† Giang: Message: session not created: cannot connect to chrome at 127.0.0.1:64886\n",
      "from session not created: This version of ChromeDriver only supports Chrome version 142\n",
      "Current browser version is 141.0.7390.123; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x4b58c3\n",
      "\t0x4b5904\n",
      "\t0x2ce76d\n",
      "\t0x30b20d\n",
      "\t0x30a159\n",
      "\t0x30008f\n",
      "\t0x2ffeb6\n",
      "\t0x348993\n",
      "\t0x34830a\n",
      "\t0x33c766\n",
      "\t0x30dac0\n",
      "\t0x30ede4\n",
      "\t0x737974\n",
      "\t0x732bea\n",
      "\t0x4de5b4\n",
      "\t0x4cdd28\n",
      "\t0x4d4d8d\n",
      "\t0x4bded8\n",
      "\t0x4be09c\n",
      "\t0x4a7d1a\n",
      "\t0x767e5d49\n",
      "\t0x77c0d6db\n",
      "\t0x77c0d661\n",
      "\n",
      "üßπ ƒê√£ ƒë√≥ng driver cho tuy·∫øn H√† Giang\n",
      "\n",
      "üöç ƒêang crawl: H√† N·ªôi ‚Üí Qu·∫£ng Ninh\n",
      "üí• L·ªói driver khi x·ª≠ l√Ω Qu·∫£ng Ninh: Message: session not created: cannot connect to chrome at 127.0.0.1:60556\n",
      "from session not created: This version of ChromeDriver only supports Chrome version 142\n",
      "Current browser version is 141.0.7390.123; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0xed58c3\n",
      "\t0xed5904\n",
      "\t0xcee76d\n",
      "\t0xd2b20d\n",
      "\t0xd2a159\n",
      "\t0xd2008f\n",
      "\t0xd1feb6\n",
      "\t0xd68993\n",
      "\t0xd6830a\n",
      "\t0xd5c766\n",
      "\t0xd2dac0\n",
      "\t0xd2ede4\n",
      "\t0x1157974\n",
      "\t0x1152bea\n",
      "\t0xefe5b4\n",
      "\t0xeedd28\n",
      "\t0xef4d8d\n",
      "\t0xedded8\n",
      "\t0xede09c\n",
      "\t0xec7d1a\n",
      "\t0x767e5d49\n",
      "\t0x77c0d6db\n",
      "\t0x77c0d661\n",
      "\n",
      "üßπ ƒê√£ ƒë√≥ng driver cho tuy·∫øn Qu·∫£ng Ninh\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 133\u001b[0m\n\u001b[0;32m    131\u001b[0m             driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müßπ ƒê√£ ƒë√≥ng driver cho tuy·∫øn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marrival_city\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ngh·ªâ ng·∫´u nhi√™n ƒë·ªÉ tr√°nh b·ªã ch·∫∑n IP\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müéØ --- HO√ÄN T·∫§T TO√ÄN B·ªò QU√Å TR√åNH CRAWL ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time, random, os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "# ====================== C·∫§U H√åNH BAN ƒê·∫¶U ======================\n",
    "URL = 'https://vexere.com/'\n",
    "\n",
    "# Danh s√°ch tuy·∫øn\n",
    "arrivals_HaNoi = ['H√† Giang', 'Qu·∫£ng Ninh', 'Thanh H√≥a', 'SaPa', 'Ninh B√¨nh']\n",
    "# arrivals_SaiGon = ['Gia Lai','B√¨nh Thu·∫≠n','Ninh Thu·∫≠n','ƒê·∫Øk L·∫Øk','Ph√∫ Y√™n','Nha Trang','B√† R·ªãa-V≈©ng T√†u']\n",
    "\n",
    "departure_city = 'H√† N·ªôi'\n",
    "days_offset = 1  # int(input(\"Nh·∫≠p s·ªë ng√†y mu·ªën crawl: \"))\n",
    "\n",
    "# L·∫•y ng√†y / th√°ng c·∫ßn crawl\n",
    "target_date = get_target_date_components(days_offset)\n",
    "day = target_date['day']\n",
    "month_year = target_date['month_year']\n",
    "month_years = month_year.replace('-', '_')\n",
    "\n",
    "print(f\"\\nüö¶ B·∫Øt ƒë·∫ßu crawl t·ª´ {departure_city} cho ng√†y: {day}/{month_year}\")\n",
    "\n",
    "# ====================== V√íNG L·∫∂P CH√çNH ======================\n",
    "for arrival_city in arrivals_HaNoi:\n",
    "\n",
    "    # --- C·∫•u h√¨nh Chrome t·ªëi ∆∞u ---\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless=new\")                   # ch·∫°y n·ªÅn, kh√¥ng m·ªü giao di·ªán\n",
    "    options.add_argument(\"--no-sandbox\")                     # gi·∫£m overhead, ƒë·∫∑c bi·ªát khi ch·∫°y server\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")          # tr√°nh crash khi RAM th·∫•p\n",
    "    options.add_argument(\"--disable-gpu\")                    # t·∫Øt GPU render\n",
    "    options.add_argument(\"--disable-software-rasterizer\")    # b·ªè v·∫Ω 3D\n",
    "    options.add_argument(\"--disable-extensions\")             # t·∫Øt extension kh√¥ng c·∫ßn thi·∫øt\n",
    "    options.add_argument(\"--disable-infobars\")               # t·∫Øt banner ‚ÄúChrome is being controlled...‚Äù\n",
    "    options.add_argument(\"--disable-popup-blocking\")         # tr√°nh popup\n",
    "    options.add_argument(\"--disable-notifications\")          # t·∫Øt th√¥ng b√°o\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")  # gi·∫£m ph√°t hi·ªán bot\n",
    "    options.add_argument(\"--window-size=1920,1080\")          # c·ªë ƒë·ªãnh viewport\n",
    "    options.add_argument(\"--start-maximized\")                # t·ªëi ∆∞u hi·ªÉn th·ªã\n",
    "    options.add_argument(\"--log-level=3\")                    # gi·∫£m log\n",
    "    options.add_argument(\"--disable-logging\")                # t·∫Øt ghi log n·ªôi b·ªô Chrome\n",
    "    options.add_argument(f\"--remote-debugging-port={random.randint(9000,9999)}\")  # tr√°nh tr√πng port\n",
    "\n",
    "    # --- T·∫Øt t·∫£i ·∫£nh, popup, plugin ƒë·ªÉ ti·∫øt ki·ªám t√†i nguy√™n ---\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.default_content_setting_values.notifications\": 2,\n",
    "        \"profile.managed_default_content_settings.stylesheets\": 1,\n",
    "        \"profile.managed_default_content_settings.cookies\": 1,\n",
    "        \"profile.managed_default_content_settings.plugins\": 2,\n",
    "        \"profile.managed_default_content_settings.popups\": 2\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    options.page_load_strategy = \"eager\"  # ch·ªâ ƒë·ª£i DOM, kh√¥ng ch·ªù to√†n b·ªô page load\n",
    "\n",
    "    # --- Kh·ªüi t·∫°o service ch·ªâ 1 l·∫ßn ---\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "\n",
    "    print(f\"\\nüöç ƒêang crawl: {departure_city} ‚Üí {arrival_city}\")\n",
    "\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.get(URL)\n",
    "\n",
    "        # 1Ô∏è‚É£ Thi·∫øt l·∫≠p filter\n",
    "        filter_success = set_search_filters(\n",
    "            driver,\n",
    "            start_city=departure_city,\n",
    "            destination_city=arrival_city,\n",
    "            days=days_offset\n",
    "        )\n",
    "\n",
    "        if not filter_success:\n",
    "            print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ ch·ªçn ng√†y cho {arrival_city}\")\n",
    "            continue\n",
    "\n",
    "        # 2Ô∏è‚É£ Click t√¨m ki·∫øm\n",
    "        time.sleep(1)\n",
    "        click_search(driver)\n",
    "\n",
    "        # 3Ô∏è‚É£ Ch·ªù trang k·∫øt qu·∫£\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".bus-item\"))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(f\"‚è∞ Kh√¥ng t√¨m th·∫•y chuy·∫øn xe n√†o cho tuy·∫øn {arrival_city}\")\n",
    "            continue\n",
    "\n",
    "        # 4Ô∏è‚É£ Click ‚ÄúXem th√™m‚Äù v√† m·ªü ƒë√°nh gi√°\n",
    "        click_load_more(driver, max_click=5)\n",
    "        expand_ratings(driver, click_prob=0.75)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        # 5Ô∏è‚É£ Parse HTML v√† l∆∞u file CSV\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        try:\n",
    "            df_trips_info = extract_all_trips(soup)\n",
    "\n",
    "            os.makedirs(\"../../data/processed\", exist_ok=True)\n",
    "            save_path = f\"../../data/processed/{departure_city}_{arrival_city}_{day}_{month_years}.csv\"\n",
    "            df_trips_info.to_csv(save_path, index=False, encoding='utf-8')\n",
    "\n",
    "            print(f\"‚úÖ L·∫•y d·ªØ li·ªáu {arrival_city} th√†nh c√¥ng! ‚Üí {save_path}\")\n",
    "\n",
    "        except Exception as e_parse:\n",
    "            os.makedirs(\"../../data/site\", exist_ok=True)\n",
    "            html_path = f\"../../data/site/{departure_city}_{arrival_city}_{day}_{month_years}_error.html\"\n",
    "            with open(html_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(soup.prettify())\n",
    "            print(f\"‚ùå L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e_parse}\\nƒê√£ l∆∞u HTML ƒë·ªÉ debug: {html_path}\")\n",
    "\n",
    "        finally:\n",
    "            del soup\n",
    "\n",
    "    except WebDriverException as e_driver:\n",
    "        print(f\"üí• L·ªói driver khi x·ª≠ l√Ω {arrival_city}: {e_driver}\")\n",
    "\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "        print(f\"üßπ ƒê√£ ƒë√≥ng driver cho tuy·∫øn {arrival_city}\")\n",
    "        time.sleep(random.uniform(5, 10))  # ngh·ªâ ng·∫´u nhi√™n ƒë·ªÉ tr√°nh b·ªã ch·∫∑n IP\n",
    "\n",
    "print(\"\\nüéØ --- HO√ÄN T·∫§T TO√ÄN B·ªò QU√Å TR√åNH CRAWL ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
